{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9WEDzYAhjDv"
      },
      "source": [
        "## In class Exercise 4\n",
        "\n",
        "The purpose of this exercise is to practice topic modeling.\n",
        "Please use the text corpus you collected in your last in-class-exercise for this exercise.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due tonight November 1st, 2023 at 11:59 PM.\n",
        "**Late submissions cannot be considered.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONVFTFI7hjDy"
      },
      "source": [
        "## (1) (10 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk; nltk.download('stopwords')\n",
        "\n",
        "!pip install --upgrade spacy"
      ],
      "metadata": {
        "id": "jX-_Ty_RBabf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "eBxKdvXQCQJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "metadata": {
        "id": "SpNV4UPzCgw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implemented on a movie dataset\n",
        "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yeNGZkqgCkU9",
        "outputId": "61abac62-a2c6-4b0e-a2a2-c3554c4b5211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  target  \\\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
              "\n",
              "            target_names  \n",
              "0              rec.autos  \n",
              "1  comp.sys.mac.hardware  \n",
              "2  comp.sys.mac.hardware  \n",
              "3          comp.graphics  \n",
              "4              sci.space  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2b3426f-1a45-4003-bc66-c5cbc75e883d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2b3426f-1a45-4003-bc66-c5cbc75e883d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2b3426f-1a45-4003-bc66-c5cbc75e883d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2b3426f-1a45-4003-bc66-c5cbc75e883d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9de6b164-9ec8-47f2-ba8d-ffcd6c1746f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9de6b164-9ec8-47f2-ba8d-ffcd6c1746f8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9de6b164-9ec8-47f2-ba8d-ffcd6c1746f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.content.values.tolist()\n",
        "\n",
        "# Remove Emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
      ],
      "metadata": {
        "id": "9U2ds_PjCph9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))"
      ],
      "metadata": {
        "id": "ou9sPaq8C3M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "metadata": {
        "id": "mfBzw--8DAix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "metadata": {
        "id": "_kT_ML3SDOWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
      ],
      "metadata": {
        "id": "V8AGi1WDDQFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "Mv0DAwAkEjFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating K topics by using LDA and summarizing the topics.\n",
        "\n",
        "coherence_scores = []\n",
        "for k in range(2, 11):  # Try different values of K\n",
        "    lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=k, random_state=100, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "    coherence_score = coherence_model_lda.get_coherence()\n",
        "    coherence_scores.append((k, coherence_score))\n",
        "\n",
        "# Find the K with the highest coherence score\n",
        "optimal_k = max(coherence_scores, key=lambda x: x[1])[0]"
      ],
      "metadata": {
        "id": "r2fdx0b1Ewho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The optimal number of topics is {optimal_k}\")\n",
        "topics = lda_model.show_topics(num_topics=optimal_k, num_words=10, formatted=False)\n",
        "for topic in topics:\n",
        "    print(f\"Topic {topic[0]}: {' | '.join(word[0] for word in topic[1])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92UhfD81JVCX",
        "outputId": "70ebbb7e-2ebe-4478-a142-a4a471dd31c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimal number of topics is 5\n",
            "Topic 8: evidence | reason | believe | faith | sense | exist | religion | claim | belief | law\n",
            "Topic 5: ax | max | choose | character | sin | monitor | motif | newsgroup | dn | gift\n",
            "Topic 9: case | issue | public | group | provide | also | cause | report | patient | number\n",
            "Topic 6: line | use | system | key | thank | need | file | program | mail | host\n",
            "Topic 3: write | line | article | say | know | get | think | go | make | organization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoGcdZHlhjD0"
      },
      "source": [
        "## (2) (10 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdQHe6PghjD0"
      },
      "outputs": [],
      "source": [
        "from gensim.models import LsiModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "coherence_scores = []\n",
        "\n",
        "for k in range(2, 11):  # Try different values of K\n",
        "    lsa_model = LsiModel(corpus=corpus, id2word=id2word, num_topics=k)\n",
        "    coherence_model = CoherenceModel(model=lsa_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append((k, coherence_score))\n",
        "\n",
        "# Find the K with the highest coherence score\n",
        "optimal_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "print(f\"The optimal number of topics is {optimal_k}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_lsa_model = LsiModel(corpus=corpus, id2word=id2word, num_topics=optimal_k)"
      ],
      "metadata": {
        "id": "Mz3NzdDL_cOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = optimal_lsa_model.show_topics(num_topics=optimal_k, num_words=10, formatted=False)\n",
        "for topic in topics:\n",
        "    print(f\"Topic {topic[0]}: {' | '.join(word[0] for word in topic[1])}\")"
      ],
      "metadata": {
        "id": "eBFNlhAW_i7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBHv9hEbhjD1"
      },
      "source": [
        "## (3) (10 points) Generate K topics by using  lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5RzChAiiJho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lda2vec"
      ],
      "metadata": {
        "id": "N4YUMSMCBMzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyLDAvis"
      ],
      "metadata": {
        "id": "xHTZATRuBdpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URiSoYHghjD2"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import lda2vec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    import seaborn\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "8j4jlarDDXHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npz = np.load(open('/content/drive/MyDrive/ProjectClg/topics.pyldavis.npz', 'r'))\n",
        "# dat = {k: v for (k, v) in npz.iteritems()}\n",
        "dat['vocab'] = dat['vocab'].tolist()\n"
      ],
      "metadata": {
        "id": "xCf62FcDKUS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lda2vec import Lda2vec\n",
        "\n",
        "coherence_scores = []\n",
        "\n",
        "for k in range(2, 11):  # Try different values of K\n",
        "    lda2vec_model = Lda2vec(n_topics=k)\n",
        "    lda2vec_model.fit(data_lemmatized)\n",
        "\n",
        "    # Calculate coherence score here (based on your lda2vec implementation)\n",
        "    coherence_score = lda2vec_model.calculate_coherence()\n",
        "    # Append coherence_score to coherence_scores list\n",
        "\n",
        "# Find the K with the highest coherence score\n",
        "optimal_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "print(f\"The optimal number of topics is {optimal_k}\")"
      ],
      "metadata": {
        "id": "j-f9jU3cd4-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda2vec_model = Lda2vec(n_topics=optimal_k)\n",
        "lda2vec_model.fit(data_lemmatized)"
      ],
      "metadata": {
        "id": "hc4xfyF_eGRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "word_vectors = lda2vec_model.word_vectors  # Get word vectors\n",
        "\n",
        "# Cluster word vectors to identify topics\n",
        "kmeans = KMeans(n_clusters=optimal_k)\n",
        "kmeans.fit(word_vectors)\n",
        "word_labels = kmeans.labels_\n",
        "\n",
        "# Print top words for each cluster\n",
        "for topic_id in range(optimal_k):\n",
        "    words_in_topic = [word for i, word in enumerate(id2word) if word_labels[i] == topic_id]\n",
        "    print(f\"Topic {topic_id}: {', '.join(words_in_topic)}\")"
      ],
      "metadata": {
        "id": "cKNkRNxXeKc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) (10 points) Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ],
      "metadata": {
        "id": "4T_I1nlDPCb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install bertopic"
      ],
      "metadata": {
        "id": "_mksf51qT-oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']"
      ],
      "metadata": {
        "id": "UG0Xo3ngUB6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "# from bertopic import UMAPer\n",
        "import umap\n",
        "\n",
        "coherence_scores = []\n",
        "\n",
        "for k in range(2, 11):  # Try different values of K\n",
        "    topic_model = BERTopic(language=\"english\", min_topic_size=5, verbose=True)\n",
        "    topics, _ = topic_model.fit_transform(docs)\n",
        "    umap_model = umap.UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
        "    umap_embeddings = umap_model.fit_transform(topics)\n",
        "    coherence_score = umap_model.score(umap_embeddings)\n",
        "    coherence_scores.append((k, coherence_score))\n",
        "\n",
        "# Find the K with the highest coherence score\n",
        "optimal_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "print(f\"The optimal number of topics is {optimal_k}\")\n"
      ],
      "metadata": {
        "id": "4GgW1OAnQ15y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model = BERTopic(language=\"english\", min_topic_size=5, verbose=True)\n",
        "topics, _ = topic_model.fit_transform(data_lemmatized)"
      ],
      "metadata": {
        "id": "e1Rtolk4ZVXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic_id, words in topic_model.get_topics().items():\n",
        "    print(f\"Topic {topic_id}: {', '.join(words)}\")"
      ],
      "metadata": {
        "id": "IQAcPoJOZWgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7tQQENUhjD2"
      },
      "source": [
        "## (5) (10 extra points) Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.\n",
        "\n",
        "Follow the guidelines from the essay to enhance your explanation:\n",
        "\n",
        "* Writing logic\n",
        "\n",
        "  Pay attention to how you express your thoughts. For example:\n",
        "\n",
        "  * Weak Writing Logic: “Artificial Intelligence is risky because it is new technology.”\n",
        "\n",
        "  * Strong Writing Logic: “Artificial Intelligence presents ethical risks such as data privacy concerns and algorithmic bias, which necessitate cautious implementation and regulation.”\n",
        "\n",
        "* Topic of sentences\n",
        "\n",
        "  * Focus and Direction: It provides a focus and sets the direction for the paragraph, ensuring that the reader knows what to expect.\n",
        "  * Reader Guidance: It serves as a guidepost for the reader, making it easier to follow the flow of ideas and arguments in the document.\n",
        "  * Support for Thesis: In academic papers, topic sentences help in elaborating or providing evidence for the thesis statement or research question.\n",
        "\n",
        "* Writing flow\n",
        "\n",
        "  * Transition: Smooth and logical transitions between sentences, paragraphs, and sections.\n",
        "  * Rhythm: Variation in sentence length and structure to maintain reader engagement.\n",
        "  * Sequence: The order of points or arguments contributes to a smooth reading experience.\n",
        "  For example:\n",
        "    * Weak Writing Flow: “We studied machine learning algorithms. Ethics are important. Data was collected.”\n",
        "    * Strong Writing Flow: “We initiated our study by focusing on machine learning algorithms. Recognizing the ethical implications, we carefully curated our data set.”"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**\n",
        "\n",
        "It's critical to evaluate the advantages and disadvantages of the four topic modeling algorithms—Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic—in order to ascertain which is more appropriate for particular use situations.\n",
        "\n",
        "Due to its interpretability, LDA is a well-established and conventional technique that is preferred. It is perfect for tasks where subject comprehension is crucial since it generates topics that are readable by humans. It can be difficult to precisely estimate the number of topics in advance, though, as LDA demands you to do.\n",
        "\n",
        "Another traditional approach, LSA, is excellent at reducing dimensionality and capturing the semantic links between concepts. It is appropriate for jobs where capturing semantic similarity is more important than subject interpretability, even though it might not provide easily interpretable topics.\n",
        "\n",
        "A new method called lda2vec finds a balance between semantic comprehension and interpretability. It makes use of word embeddings, which are capable of capturing intricate semantic associations. Although lda2vec is designed to offer more interpretable subjects than LSA, it can be computationally demanding and difficult to implement.\n",
        "\n",
        "In contrast, BERTopic is predicated on BERT embeddings, a cutting-edge language model. Because of BERT's superior language understanding abilities, it usually generates topics of a high caliber. BERTopic's capacity to automatically calculate the number of topics reduces the need for manual hyperparameter adjustment, which is one of its significant advantages. Because of this, it's perfect for jobs where output is crucial.\n",
        "\n",
        "The computing demands of the BERT topic, however, can be high during both training and inference. Additionally, because it tends to use a more \"black-box\" approach, it might not offer the same amount of interpretability as LDA.\n",
        "\n",
        "In conclusion, your unique use case and priorities will determine which topic modeling algorithm is appropriate for you. LDA is a good option if the number of topics is known ahead of time and interpretability is your primary priority. Tasks that prioritize collecting semantic linkages are a good fit for LSA. Although it requires more complicated implementation, lda2vec offers a balance between interpretability and semantic understanding. Even if some interpretability must be given up, BERTopic's fast performance and automatic topic number selection make it the perfect choice for applications where results are crucial. In the end, the decision should be in line with the goals and trade-offs of your particular use case."
      ],
      "metadata": {
        "id": "MDfaklQBacOz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}